{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading DataFrames from multiple files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When data is spread among several files, you usually invoke pandas' read_csv() (or a similar data import function) multiple times to load the data into several DataFrames.\n",
    "\n",
    "The data files for this example have been derived from a list of Olympic medals awarded between 1896 & 2008 compiled by the Guardian.\n",
    "\n",
    "The column labels of each DataFrame are NOC, Country, & Total where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won (bronze, silver, or gold)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Import pandas as pd.\n",
    "Read the file 'Bronze.csv' into a DataFrame called bronze.\n",
    "Read the file 'Silver.csv' into a DataFrame called silver.\n",
    "Read the file 'Gold.csv' into a DataFrame called gold.\n",
    "Print the first 5 rows of the DataFrame gold. This has been done for you to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv(\"Bronze.csv\")\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv('Silver.csv')\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv(\"Gold.csv\")\n",
    "\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading DataFrames from multiple files in a loop"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loading data from multiple files into DataFrames is more efficient in a loop or a list comprehension.\n",
    "\n",
    "Notice that this approach is not restricted to working with CSV files. That is, even if your data comes in other formats, as long as pandas has a suitable data import function, you can apply a loop or comprehension to generate a list of DataFrames imported from the source files.\n",
    "\n",
    "Here, you'll continue working with The Guardian's Olympic medal dataset."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Create a list of file names called filenames with three strings 'Gold.csv', 'Silver.csv', & 'Bronze.csv'. This has been done for you.\n",
    "Use a for loop to create another list called dataframes containing the three DataFrames loaded from filenames:\n",
    "Iterate over filenames.\n",
    "Read each CSV file in filenames into a DataFrame and append it to dataframes by using pd.read_csv() inside a call to .append().\n",
    "Print the first 5 rows of the first DataFrame of the list dataframes. This has been done for you, so hit 'Submit Answer' to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "filenames = ['Gold.csv', 'Silver.csv', 'Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "datframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames from multiple data files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercise, you'll combine the three DataFrames from earlier exercises - gold, silver, & bronze - into a single DataFrame called medals. The approach you'll use here is clumsy. you'll see various powerful methods that are frequently used in practice for concatenating or merging DataFrames.\n",
    "\n",
    "Remember, the column labels of each DataFrame are NOC, Country, and Total, where NOC is a three-letter code for the name of the country and Total is the number of medals of that type won."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Construct a copy of the DataFrame gold called medals using the .copy() method.\n",
    "Create a list called new_labels with entries 'NOC', 'Country', & 'Gold'. This is the same as the column labels from gold with the column label 'Total' replaced by 'Gold'.\n",
    "Rename the columns of medals by assigning new_labels to medals.columns.\n",
    "Create new columns 'Silver' and 'Bronze' in medals using silver['Total'] & bronze['Total'].\n",
    "Print the top 5 rows of the final DataFrame medals. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels: new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting DataFrame with the Index & columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is often useful to rearrange the sequence of the rows of a DataFrame by sorting. You don't have to implement these yourself; the principal methods for doing this are .sort_index() and .sort_values().\n",
    "\n",
    "You'll use these methods with a DataFrame of temperature values indexed by month names. You'll sort the rows alphabetically using the Index and numerically using a column. Notice, for this data, the original ordering is probably most useful and intuitive: the purpose here is for you to understand what the sorting methods do."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Read 'monthly_max_temp.csv' into a DataFrame called weather1 with 'Month' as the index.\n",
    "Sort the index of weather1 in alphabetical order using the .sort_index() method and store the result in weather2.\n",
    "Sort the index of weather1 in reverse alphabetical order by specifying the additional keyword argument ascending=False inside .sort_index().\n",
    "Use the .sort_values() method to sort weather1 in increasing numerical order according to the values of the column 'Max TemperatureF'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       record_id  day  year  AverageTemperatureFahr  \\\n",
      "month                                                 \n",
      "1         474376    1  1853                     NaN   \n",
      "2         474377    1  1853                     NaN   \n",
      "3         474378    1  1853                     NaN   \n",
      "4         474379    1  1853                     NaN   \n",
      "5         474380    1  1853                     NaN   \n",
      "\n",
      "       AverageTemperatureUncertaintyFahr      City country_id      Country  \\\n",
      "month                                                                        \n",
      "1                                    NaN  Auckland        NEW  New Zealand   \n",
      "2                                    NaN  Auckland        NEW  New Zealand   \n",
      "3                                    NaN  Auckland        NEW  New Zealand   \n",
      "4                                    NaN  Auckland        NEW  New Zealand   \n",
      "5                                    NaN  Auckland        NEW  New Zealand   \n",
      "\n",
      "      Latitude Longitude  \n",
      "month                     \n",
      "1       36.17S   175.03E  \n",
      "2       36.17S   175.03E  \n",
      "3       36.17S   175.03E  \n",
      "4       36.17S   175.03E  \n",
      "5       36.17S   175.03E  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "weather1 = pd.read_csv('monthly_max_temp.csv', index_col='month')\n",
    "\n",
    "# Print the head of weather1\n",
    "print(weather1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       record_id  day  year  AverageTemperatureFahr  \\\n",
      "month                                                 \n",
      "1         474376    1  1853                     NaN   \n",
      "1        5412831    1  1761                 29.3288   \n",
      "1        1346967    1  1843                 75.4772   \n",
      "1        5412843    1  1762                 39.0758   \n",
      "1        5412855    1  1763                 28.8176   \n",
      "\n",
      "       AverageTemperatureUncertaintyFahr      City country_id      Country  \\\n",
      "month                                                                        \n",
      "1                                    NaN  Auckland        NEW  New Zealand   \n",
      "1                                41.2880     Odesa        UKR      Ukraine   \n",
      "1                                34.8566    Canoas        BRA       Brazil   \n",
      "1                                37.1462     Odesa        UKR      Ukraine   \n",
      "1                                41.2178     Odesa        UKR      Ukraine   \n",
      "\n",
      "      Latitude Longitude  \n",
      "month                     \n",
      "1       36.17S   175.03E  \n",
      "1       45.81N    31.15E  \n",
      "1       29.74S    51.69W  \n",
      "1       45.81N    31.15E  \n",
      "1       45.81N    31.15E  \n"
     ]
    }
   ],
   "source": [
    "# Sort the index of weather1 in alphabetical order: weather2\n",
    "weather2 = weather1.sort_index()\n",
    "\n",
    "# Print the head of weather2\n",
    "print(weather2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       record_id  day  year  AverageTemperatureFahr  \\\n",
      "month                                                 \n",
      "12       5413598    1  1824                 44.6720   \n",
      "12       3503394    1  2008                 68.5814   \n",
      "12       3503310    1  2001                 66.0164   \n",
      "12       1347782    1  1910                 71.3660   \n",
      "12       5700481    1  1843                 40.2512   \n",
      "\n",
      "       AverageTemperatureUncertaintyFahr          City country_id  \\\n",
      "month                                                               \n",
      "12                               39.4412         Odesa        UKR   \n",
      "12                               32.4842  Johannesburg        SOU   \n",
      "12                               32.7416  Johannesburg        SOU   \n",
      "12                               34.1690           NaN        NaN   \n",
      "12                               37.2704         Paris        FRA   \n",
      "\n",
      "            Country Latitude Longitude  \n",
      "month                                   \n",
      "12          Ukraine   45.81N    31.15E  \n",
      "12     South Africa   26.52S    28.66E  \n",
      "12     South Africa   26.52S    28.66E  \n",
      "12              NaN   29.74S    51.69W  \n",
      "12           France   49.03N     2.45E  \n"
     ]
    }
   ],
   "source": [
    "# Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# Print the head of weather3\n",
    "print(weather3.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       record_id  day  year  AverageTemperatureFahr  \\\n",
      "month                                                 \n",
      "2        3819490    1  1929                  2.8562   \n",
      "1        3819645    1  1942                  3.5456   \n",
      "1        3820185    1  1987                  4.5050   \n",
      "1        3819897    1  1963                  4.8344   \n",
      "1        3819057    1  1893                  5.0378   \n",
      "\n",
      "       AverageTemperatureUncertaintyFahr  City country_id  Country Latitude  \\\n",
      "month                                                                         \n",
      "2                                33.0872  Kiev        UKR  Ukraine   50.63N   \n",
      "1                                33.7946  Kiev        UKR  Ukraine   50.63N   \n",
      "1                                32.7956  Kiev        UKR  Ukraine   50.63N   \n",
      "1                                33.6092  Kiev        UKR  Ukraine   50.63N   \n",
      "1                                33.0386  Kiev        UKR  Ukraine   50.63N   \n",
      "\n",
      "      Longitude  \n",
      "month            \n",
      "2        31.69E  \n",
      "1        31.69E  \n",
      "1        31.69E  \n",
      "1        31.69E  \n",
      "1        31.69E  \n"
     ]
    }
   ],
   "source": [
    "# Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "weather4 = weather1.sort_values('AverageTemperatureFahr')\n",
    "\n",
    "# Print the head of weather4\n",
    "print(weather4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing DataFrame from a list"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sorting methods are not the only way to change DataFrame Indexes. There is also the .reindex() method.\n",
    "\n",
    "In this exercise, you'll reindex a DataFrame of quarterly-sampled mean temperature values to contain monthly samples (this is an example of upsampling or increasing the rate of samples, which you may recall from the pandas Foundations course).\n",
    "\n",
    "The original data has the first month's abbreviation of the quarter (three-month interval) on the Index, namely Apr, Jan, Jul, and Sep. This data has been loaded into a DataFrame called weather1 and has been printed in its entirety in the IPython Shell. Notice it has only four rows (corresponding to the first month of each quarter) and that the rows are not sorted chronologically.\n",
    "\n",
    "You'll initially use a list of all twelve month abbreviations and subsequently apply the .ffill() method to forward-fill the null entries when upsampling. This list of month abbreviations has been pre-loaded as year."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Reorder the rows of weather1 using the .reindex() method with the list year as the argument, which contains the abbreviations for each month.\n",
    "Reorder the rows of weather1 just as you did above, this time chaining the .ffill() method to replace the null values with the last preceding non-null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month  record_id  day  AverageTemperatureFahr  \\\n",
      "year                                                  \n",
      "1853      1     474376    1                     NaN   \n",
      "1853      2     474377    1                     NaN   \n",
      "1853      3     474378    1                     NaN   \n",
      "1853      4     474379    1                     NaN   \n",
      "1853      5     474380    1                     NaN   \n",
      "1853      6     474381    1                 51.9062   \n",
      "1853      7     474382    1                 52.3886   \n",
      "1853      8     474383    1                 52.8530   \n",
      "1853      9     474384    1                 52.5776   \n",
      "1853     10     474385    1                 54.8726   \n",
      "1853     11     474386    1                 56.6888   \n",
      "1853     12     474387    1                 59.8460   \n",
      "1854      1     474388    1                 64.5908   \n",
      "1854      2     474389    1                 65.3720   \n",
      "1854      3     474390    1                 64.9688   \n",
      "1854      4     474391    1                 59.9270   \n",
      "1854      5     474392    1                 57.5042   \n",
      "1854      6     474393    1                 54.5180   \n",
      "1854      7     474394    1                 53.1914   \n",
      "1854      8     474395    1                 52.8044   \n",
      "1854      9     474396    1                 53.3912   \n",
      "1854     10     474397    1                 54.7538   \n",
      "1854     11     474398    1                 57.3170   \n",
      "1854     12     474399    1                 60.0296   \n",
      "1855      1     474400    1                 63.3578   \n",
      "1855      2     474401    1                 64.3460   \n",
      "1855      3     474402    1                 63.6584   \n",
      "1855      4     474403    1                 61.5848   \n",
      "1855      5     474404    1                 58.0028   \n",
      "1855      6     474405    1                 54.8420   \n",
      "...     ...        ...  ...                     ...   \n",
      "2011      4    8258701    1                 50.4590   \n",
      "2011      5    8258702    1                 55.7690   \n",
      "2011      6    8258703    1                 63.0032   \n",
      "2011      7    8258704    1                 62.0420   \n",
      "2011      8    8258705    1                 64.8536   \n",
      "2011      9    8258706    1                 59.2196   \n",
      "2011     10    8258707    1                 47.6726   \n",
      "2011     11    8258708    1                 38.6870   \n",
      "2011     12    8258709    1                 36.2732   \n",
      "2012      1    8258710    1                 31.8830   \n",
      "2012      2    8258711    1                 23.2502   \n",
      "2012      3    8258712    1                 41.8460   \n",
      "2012      4    8258713    1                 46.7348   \n",
      "2012      5    8258714    1                 57.8606   \n",
      "2012      6    8258715    1                 60.3392   \n",
      "2012      7    8258716    1                 65.5178   \n",
      "2012      8    8258717    1                 64.9832   \n",
      "2012      9    8258718    1                 57.1946   \n",
      "2012     10    8258719    1                 46.5872   \n",
      "2012     11    8258720    1                 41.6066   \n",
      "2012     12    8258721    1                 29.5070   \n",
      "2013      1    8258722    1                 28.4612   \n",
      "2013      2    8258723    1                 30.5168   \n",
      "2013      3    8258724    1                 29.9480   \n",
      "2013      4    8258725    1                 46.2902   \n",
      "2013      5    8258726    1                 55.0544   \n",
      "2013      6    8258727    1                 61.1672   \n",
      "2013      7    8258728    1                 66.7706   \n",
      "2013      8    8258729    1                 64.5656   \n",
      "2013      9    8258730    1                     NaN   \n",
      "\n",
      "      AverageTemperatureUncertaintyFahr      City country_id      Country  \\\n",
      "year                                                                        \n",
      "1853                                NaN  Auckland        NEW  New Zealand   \n",
      "1853                                NaN  Auckland        NEW  New Zealand   \n",
      "1853                                NaN  Auckland        NEW  New Zealand   \n",
      "1853                                NaN  Auckland        NEW  New Zealand   \n",
      "1853                                NaN  Auckland        NEW  New Zealand   \n",
      "1853                            36.9572  Auckland        NEW  New Zealand   \n",
      "1853                            34.5488  Auckland        NEW  New Zealand   \n",
      "1853                            33.5498  Auckland        NEW  New Zealand   \n",
      "1853                            33.6380  Auckland        NEW  New Zealand   \n",
      "1853                            33.9836  Auckland        NEW  New Zealand   \n",
      "1853                            34.2518  Auckland        NEW  New Zealand   \n",
      "1853                            37.5062  Auckland        NEW  New Zealand   \n",
      "1854                            36.2300  Auckland        NEW  New Zealand   \n",
      "1854                            35.6576  Auckland        NEW  New Zealand   \n",
      "1854                            35.3966  Auckland        NEW  New Zealand   \n",
      "1854                            35.2022  Auckland        NEW  New Zealand   \n",
      "1854                            34.5110  Auckland        NEW  New Zealand   \n",
      "1854                            34.7972  Auckland        NEW  New Zealand   \n",
      "1854                            35.0240  Auckland        NEW  New Zealand   \n",
      "1854                            34.3544  Auckland        NEW  New Zealand   \n",
      "1854                            33.6830  Auckland        NEW  New Zealand   \n",
      "1854                            37.4108  Auckland        NEW  New Zealand   \n",
      "1854                            35.0024  Auckland        NEW  New Zealand   \n",
      "1854                            35.9240  Auckland        NEW  New Zealand   \n",
      "1855                            36.0716  Auckland        NEW  New Zealand   \n",
      "1855                            37.1300  Auckland        NEW  New Zealand   \n",
      "1855                            34.3058  Auckland        NEW  New Zealand   \n",
      "1855                            34.7594  Auckland        NEW  New Zealand   \n",
      "1855                            34.1996  Auckland        NEW  New Zealand   \n",
      "1855                            33.7568  Auckland        NEW  New Zealand   \n",
      "...                                 ...       ...        ...          ...   \n",
      "2011                            32.3978   Wroclaw        POL       Poland   \n",
      "2011                            32.4410   Wroclaw        POL       Poland   \n",
      "2011                            32.5886   Wroclaw        POL       Poland   \n",
      "2011                            32.6876   Wroclaw        POL       Poland   \n",
      "2011                            32.5508   Wroclaw        POL       Poland   \n",
      "2011                            32.3654   Wroclaw        POL       Poland   \n",
      "2011                            32.2808   Wroclaw        POL       Poland   \n",
      "2011                            32.5472   Wroclaw        POL       Poland   \n",
      "2011                            32.7236   Wroclaw        POL       Poland   \n",
      "2012                            32.9576   Wroclaw        POL       Poland   \n",
      "2012                            32.4158   Wroclaw        POL       Poland   \n",
      "2012                            32.2520   Wroclaw        POL       Poland   \n",
      "2012                            32.6210   Wroclaw        POL       Poland   \n",
      "2012                            32.6102   Wroclaw        POL       Poland   \n",
      "2012                            32.9306   Wroclaw        POL       Poland   \n",
      "2012                            32.5598   Wroclaw        POL       Poland   \n",
      "2012                            32.6354   Wroclaw        POL       Poland   \n",
      "2012                            32.5094   Wroclaw        POL       Poland   \n",
      "2012                            32.5940   Wroclaw        POL       Poland   \n",
      "2012                            32.7992   Wroclaw        POL       Poland   \n",
      "2012                            32.3132   Wroclaw        POL       Poland   \n",
      "2013                            32.6318   Wroclaw        POL       Poland   \n",
      "2013                            32.9576   Wroclaw        POL       Poland   \n",
      "2013                            32.4536   Wroclaw        POL       Poland   \n",
      "2013                            32.2808   Wroclaw        POL       Poland   \n",
      "2013                            32.4896   Wroclaw        POL       Poland   \n",
      "2013                            32.3330   Wroclaw        POL       Poland   \n",
      "2013                            32.5706   Wroclaw        POL       Poland   \n",
      "2013                            32.4842   Wroclaw        POL       Poland   \n",
      "2013                                NaN   Wroclaw        POL       Poland   \n",
      "\n",
      "     Latitude Longitude  \n",
      "year                     \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1853   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1854   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "1855   36.17S   175.03E  \n",
      "...       ...       ...  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2011   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2012   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "2013   50.63N    16.48E  \n",
      "\n",
      "[48470 rows x 10 columns]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'year' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-a7f6f7880dc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Reindex weather1 using the list year with forward-fill: weather3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mweather3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweather1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mffill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Print weather3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'year' is not defined"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reindex weather1 using the list year: weather2\n",
    "weather2 = weather1.reset_index()\n",
    "weather2 = weather2.set_index('year')\n",
    "\n",
    "# Print weather2\n",
    "print(weather2)\n",
    "\n",
    "# Reindex weather1 using the list year with forward-fill: weather3\n",
    "weather3 = weather1.reindex(year).ffill()\n",
    "\n",
    "# Print weather3\n",
    "print(weather3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reindexing using another DataFrame Index"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Another common technique is to reindex a DataFrame using the Index of another DataFrame. The DataFrame.reindex() method can accept the Index of a DataFrame or Series as input. You can access the Index of a DataFrame with its .index attribute.\n",
    "\n",
    "The Baby Names Dataset from data.gov summarizes counts of names (with genders) from births registered in the US since 1881. In this exercise, you will start with two baby-names DataFrames names_1981 and names_1881 loaded for you.\n",
    "\n",
    "The DataFrames names_1981 and names_1881 both have a MultiIndex with levels name and gender giving unique labels to counts in each row. If you're interested in seeing how the MultiIndexes were set up, names_1981 and names_1881 were read in using the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_1981 = pd.read_csv('names1981.csv', header=None, names=['name','gender','count'], index_col=(0,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "As you can see by looking at their shapes, which have been printed in the IPython Shell, the DataFrame corresponding to 1981 births is much larger, reflecting the greater diversity of names in 1981 as compared to 1881.\n",
    "\n",
    "Your job here is to use the DataFrame .reindex() and .dropna() methods to make a DataFrame common_names counting names from 1881 that were still popular in 1981."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Create a new DataFrame common_names by reindexing names_1981 using the Index of the DataFrame names_1881 of older names.\n",
    "Print the shape of the new common_names DataFrame. This has been done for you. It should be the same as that of names_1881.\n",
    "Drop the rows of common_names that have null counts using the .dropna() method. These rows correspond to names that fell out of fashion between 1881 & 1981.\n",
    "Print the shape of the reassigned common_names DataFrame. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1981.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 1)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna()\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting in arithmetic formulas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercise, you'll work with weather data pulled from wunderground.com. The DataFrame weather has been pre-loaded along with pandas as pd. It has 365 rows (observed each day of the year 2013 in Pittsburgh, PA) and 22 columns reflecting different weather measurements each day.\n",
    "\n",
    "You'll subset a collection of columns related to temperature measurements in degrees Fahrenheit, convert them to degrees Celsius, and relabel the columns of the new DataFrame to reflect the change of units.\n",
    "\n",
    "Remember, ordinary arithmetic operators (like +, -, *, and /) broadcast scalar values to conforming DataFrames when combining scalars & DataFrames in arithmetic expressions. Broadcasting also works with pandas Series and NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Create a new DataFrame temps_f by extracting the columns 'Min TemperatureF', 'Mean TemperatureF', & 'Max TemperatureF' from weather as a new DataFrame temps_f. To do this, pass the relevant columns as a list to weather[].\n",
    "Create a new DataFrame temps_c from temps_f using the formula (temps_f - 32) * 5/9.\n",
    "Rename the columns of temps_c to replace 'F' with 'C' using the .str.replace('F', 'C') method on temps_c.columns.\n",
    "Print the first 5 rows of DataFrame temps_c. This has been done for you, so hit 'Submit Answer' to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Min TemperatureF' 'Mean TemperatureF' 'Max TemperatureF'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-087c4546dfc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract selected columns from weather as new DataFrame: temps_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtemps_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweather1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Min TemperatureF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Mean TemperatureF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Max TemperatureF'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Convert temps_f to celsius: temps_c\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtemps_c\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtemps_f\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2681\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2682\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2683\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2724\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2725\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2726\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2727\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1325\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[1;32m-> 1327\u001b[1;33m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[0;32m   1328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Min TemperatureF' 'Mean TemperatureF' 'Max TemperatureF'] not in index\""
     ]
    }
   ],
   "source": [
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "temps_f = weather1[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f - 32) * 5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = temps_c.columns.str.replace('F', 'C')\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing percentage growth of GDP"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Your job in this exercise is to compute the yearly percent-change of US GDP (Gross Domestic Product) since 2008.\n",
    "\n",
    "The data has been obtained from the Federal Reserve Bank of St. Louis and is available in the file GDP.csv, which contains quarterly data; you will resample it to annual sampling and then compute the annual growth of GDP. For a refresher on resampling, check out the relevant material from pandas Foundations."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Read the file 'GDP.csv' into a DataFrame called gdp.\n",
    "Use parse_dates=True and index_col='DATE'.\n",
    "Create a DataFrame post2008 by slicing gdp such that it comprises all rows from 2008 onward.\n",
    "Print the last 8 rows of the slice post2008. This has been done for you. This data has quarterly frequency so the indices are separated by three-month intervals.\n",
    "Create the DataFrame yearly by resampling the slice post2008 by year. Remember, you need to chain .resample() (using the alias 'A' for annual frequency) with some kind of aggregation; you will use the aggregation method .last() to select the last element when resampling.\n",
    "Compute the percentage growth of the resampled DataFrame yearly with .pct_change() * 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1947-01-01</th>\n",
       "      <td>243.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-04-01</th>\n",
       "      <td>246.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-07-01</th>\n",
       "      <td>250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-10-01</th>\n",
       "      <td>260.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-01-01</th>\n",
       "      <td>266.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-04-01</th>\n",
       "      <td>272.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-07-01</th>\n",
       "      <td>279.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1948-10-01</th>\n",
       "      <td>280.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>275.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04-01</th>\n",
       "      <td>271.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-07-01</th>\n",
       "      <td>273.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-10-01</th>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-01-01</th>\n",
       "      <td>281.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-04-01</th>\n",
       "      <td>290.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-07-01</th>\n",
       "      <td>308.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950-10-01</th>\n",
       "      <td>320.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-01-01</th>\n",
       "      <td>336.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-04-01</th>\n",
       "      <td>344.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-07-01</th>\n",
       "      <td>351.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951-10-01</th>\n",
       "      <td>356.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952-01-01</th>\n",
       "      <td>360.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952-04-01</th>\n",
       "      <td>361.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952-07-01</th>\n",
       "      <td>368.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1952-10-01</th>\n",
       "      <td>381.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953-01-01</th>\n",
       "      <td>388.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953-04-01</th>\n",
       "      <td>392.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953-07-01</th>\n",
       "      <td>391.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1953-10-01</th>\n",
       "      <td>386.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-01-01</th>\n",
       "      <td>385.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954-04-01</th>\n",
       "      <td>386.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>14383.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-01</th>\n",
       "      <td>14340.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01</th>\n",
       "      <td>14384.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-01</th>\n",
       "      <td>14566.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01</th>\n",
       "      <td>14681.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>14888.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>15057.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-01</th>\n",
       "      <td>15230.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01</th>\n",
       "      <td>15238.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-04-01</th>\n",
       "      <td>15460.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01</th>\n",
       "      <td>15587.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-01</th>\n",
       "      <td>15785.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01</th>\n",
       "      <td>15973.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-01</th>\n",
       "      <td>16121.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-01</th>\n",
       "      <td>16227.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-01</th>\n",
       "      <td>16297.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>16475.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-01</th>\n",
       "      <td>16541.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-07-01</th>\n",
       "      <td>16749.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>16999.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>17025.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>17285.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-07-01</th>\n",
       "      <td>17569.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-01</th>\n",
       "      <td>17692.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-01</th>\n",
       "      <td>17783.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>17998.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>18141.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01</th>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>18281.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>18436.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              VALUE\n",
       "DATE               \n",
       "1947-01-01    243.1\n",
       "1947-04-01    246.3\n",
       "1947-07-01    250.1\n",
       "1947-10-01    260.3\n",
       "1948-01-01    266.2\n",
       "1948-04-01    272.9\n",
       "1948-07-01    279.5\n",
       "1948-10-01    280.7\n",
       "1949-01-01    275.4\n",
       "1949-04-01    271.7\n",
       "1949-07-01    273.3\n",
       "1949-10-01    271.0\n",
       "1950-01-01    281.2\n",
       "1950-04-01    290.7\n",
       "1950-07-01    308.5\n",
       "1950-10-01    320.3\n",
       "1951-01-01    336.4\n",
       "1951-04-01    344.5\n",
       "1951-07-01    351.8\n",
       "1951-10-01    356.6\n",
       "1952-01-01    360.2\n",
       "1952-04-01    361.4\n",
       "1952-07-01    368.1\n",
       "1952-10-01    381.2\n",
       "1953-01-01    388.5\n",
       "1953-04-01    392.3\n",
       "1953-07-01    391.7\n",
       "1953-10-01    386.5\n",
       "1954-01-01    385.9\n",
       "1954-04-01    386.7\n",
       "...             ...\n",
       "2009-01-01  14383.9\n",
       "2009-04-01  14340.4\n",
       "2009-07-01  14384.1\n",
       "2009-10-01  14566.5\n",
       "2010-01-01  14681.1\n",
       "2010-04-01  14888.6\n",
       "2010-07-01  15057.7\n",
       "2010-10-01  15230.2\n",
       "2011-01-01  15238.4\n",
       "2011-04-01  15460.9\n",
       "2011-07-01  15587.1\n",
       "2011-10-01  15785.3\n",
       "2012-01-01  15973.9\n",
       "2012-04-01  16121.9\n",
       "2012-07-01  16227.9\n",
       "2012-10-01  16297.3\n",
       "2013-01-01  16475.4\n",
       "2013-04-01  16541.4\n",
       "2013-07-01  16749.3\n",
       "2013-10-01  16999.9\n",
       "2014-01-01  17025.2\n",
       "2014-04-01  17285.6\n",
       "2014-07-01  17569.4\n",
       "2014-10-01  17692.2\n",
       "2015-01-01  17783.6\n",
       "2015-04-01  17998.3\n",
       "2015-07-01  18141.9\n",
       "2015-10-01  18222.8\n",
       "2016-01-01  18281.6\n",
       "2016-04-01  18436.5\n",
       "\n",
       "[278 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read 'GDP.csv' into a DataFrame: gdp\n",
    "gdp = pd.read_csv('gdp_usa.csv', parse_dates=True, index_col='DATE')\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n"
     ]
    }
   ],
   "source": [
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp.loc['2008':]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n"
     ]
    }
   ],
   "source": [
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    }
   ],
   "source": [
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting currency of stocks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this exercise, stock prices in US Dollars for the S&P 500 in 2015 have been obtained from Yahoo Finance. The files sp500.csv for sp500 and exchange.csv for the exchange rates are both provided to you.\n",
    "\n",
    "Using the daily exchange rate to Pounds Sterling, your task is to convert both the Open and Close column prices."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INSTRUCTIONS\n",
    "\n",
    "Read the DataFrames sp500 & exchange from the files 'sp500.csv' & 'exchange.csv' respectively..\n",
    "Use parse_dates=True and index_col='Date'.\n",
    "Extract the columns 'Open' & 'Close' from the DataFrame sp500 as a new DataFrame dollars and print the first 5 rows.\n",
    "Construct a new DataFrame pounds by converting US dollars to British pounds. You'll use the .multiply() method of dollars with exchange['GBP/USD'] and axis='rows'\n",
    "Print the first 5 rows of the new DataFrame pounds. This has been done for you, so hit 'Submit Answer' to see the results!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open         High          Low        Close      Volume  \\\n",
      "Date                                                                         \n",
      "2015-01-02  2058.899902  2072.360107  2046.040039  2058.199951  2708700000   \n",
      "2015-01-05  2054.439941  2054.439941  2017.339966  2020.579956  3799120000   \n",
      "2015-01-06  2022.150024  2030.250000  1992.439941  2002.609985  4460110000   \n",
      "2015-01-07  2005.550049  2029.609985  2005.550049  2025.900024  3805480000   \n",
      "2015-01-08  2030.609985  2064.080078  2030.609985  2062.139893  3934010000   \n",
      "\n",
      "              Adj Close  \n",
      "Date                     \n",
      "2015-01-02  2058.199951  \n",
      "2015-01-05  2020.579956  \n",
      "2015-01-06  2002.609985  \n",
      "2015-01-07  2025.900024  \n",
      "2015-01-08  2062.139893  \n",
      "            GBP/USD\n",
      "Date               \n",
      "2015-01-02  0.65101\n",
      "2015-01-05  0.65644\n",
      "2015-01-06  0.65896\n",
      "2015-01-07  0.66344\n",
      "2015-01-08  0.66151\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read 'sp500.csv' into a DataFrame: sp500\n",
    "sp500 = pd.read_csv('sp500.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# Read 'exchange.csv' into a DataFrame: exchange\n",
    "exchange = pd.read_csv('exchange.csv', parse_dates=True, index_col='Date')\n",
    "\n",
    "# print the head of 'sp500' and 'exchange'\n",
    "print(sp500.head())\n",
    "print(exchange.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n"
     ]
    }
   ],
   "source": [
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500[['Open', 'Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    }
   ],
   "source": [
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'],axis='rows')\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
